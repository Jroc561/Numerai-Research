{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Making your first submission on Numerai",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit ('Portfolio-Tracker': pipenv)",
      "metadata": {
        "interpreter": {
          "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUD4ylfaLZA6"
      },
      "source": [
        "# Making your first submission on Numerai\n",
        "\n",
        "## Introduction \n",
        "This tutorial will go over how to create your first submission on Numerai.\n",
        "\n",
        "## Overview\n",
        "\n",
        "1. Using this notebook\n",
        "2. Download the datasets\n",
        "3. Train your first model\n",
        "4. Generate your first predictions\n",
        "4. Make your first submission\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dioJyoTnxEm3"
      },
      "source": [
        "\n",
        "## 1. Using this notebook \n",
        "\n",
        "This is an interactive notebook. You can execute code in each cell by pressing `shift+enter`. This requires you to login with your Google account.\n",
        "\n",
        "In order to make changes, you need to make a copy by `File -> Save a copy in Drive`.\n",
        "\n",
        "Let's start off by installing and importing our dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaNpcfNkKUg_"
      },
      "source": [
        "# import dependencies\n",
        "import pandas as pd\n",
        "import numerapi\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uUN-aE_08kW"
      },
      "source": [
        "## 2. Download the datasets\n",
        "\n",
        "### Datasets \n",
        "*   `training_data` is used to train your model\n",
        "*   `tournament_data` is used to evaluate your model\n",
        "\n",
        "### Column descriptions\n",
        "*   id: a randomized id that corresponds to a stock \n",
        "*   era: a period of time\n",
        "*   data_type: either `train`, `validation`, `test`, or `live` \n",
        "*   feature_*: abstract financial features of the stock \n",
        "*   target: abstract measure of stock performance\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyB8NsbUNNWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "a8d06706-0fbc-4b5c-deb2-29f5e5947a8a"
      },
      "source": [
        "# download the latest training dataset (takes around 30s)\n",
        "training_data = pd.read_csv(\"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_training_data.csv.xz\")\n",
        "training_data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id   era data_type  feature_intelligence1  \\\n",
              "0  n000315175b67977  era1     train                   0.00   \n",
              "1  n0014af834a96cdd  era1     train                   0.00   \n",
              "2  n001c93979ac41d4  era1     train                   0.25   \n",
              "3  n0034e4143f22a13  era1     train                   1.00   \n",
              "4  n00679d1a636062f  era1     train                   0.25   \n",
              "\n",
              "   feature_intelligence2  feature_intelligence3  feature_intelligence4  \\\n",
              "0                   0.50                   0.25                   0.00   \n",
              "1                   0.00                   0.00                   0.25   \n",
              "2                   0.50                   0.25                   0.25   \n",
              "3                   0.00                   0.00                   0.50   \n",
              "4                   0.25                   0.25                   0.25   \n",
              "\n",
              "   feature_intelligence5  feature_intelligence6  feature_intelligence7  ...  \\\n",
              "0                    0.5                   0.25                   0.25  ...   \n",
              "1                    0.5                   0.00                   0.00  ...   \n",
              "2                    1.0                   0.75                   0.75  ...   \n",
              "3                    0.5                   0.25                   0.25  ...   \n",
              "4                    0.0                   0.25                   0.50  ...   \n",
              "\n",
              "   feature_wisdom38  feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n",
              "0              1.00              1.00              0.75              0.50   \n",
              "1              1.00              1.00              0.00              0.00   \n",
              "2              0.25              0.50              0.00              0.00   \n",
              "3              1.00              1.00              0.75              0.75   \n",
              "4              0.75              0.75              0.25              0.50   \n",
              "\n",
              "   feature_wisdom42  feature_wisdom43  feature_wisdom44  feature_wisdom45  \\\n",
              "0              0.75              0.50              1.00              0.50   \n",
              "1              0.75              0.25              0.00              0.25   \n",
              "2              0.50              1.00              0.00              0.25   \n",
              "3              1.00              1.00              0.75              1.00   \n",
              "4              0.75              0.00              0.50              0.25   \n",
              "\n",
              "   feature_wisdom46  target  \n",
              "0              0.75    0.50  \n",
              "1              1.00    0.25  \n",
              "2              0.75    0.25  \n",
              "3              1.00    0.25  \n",
              "4              0.75    0.75  \n",
              "\n",
              "[5 rows x 314 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>era</th>\n      <th>data_type</th>\n      <th>feature_intelligence1</th>\n      <th>feature_intelligence2</th>\n      <th>feature_intelligence3</th>\n      <th>feature_intelligence4</th>\n      <th>feature_intelligence5</th>\n      <th>feature_intelligence6</th>\n      <th>feature_intelligence7</th>\n      <th>...</th>\n      <th>feature_wisdom38</th>\n      <th>feature_wisdom39</th>\n      <th>feature_wisdom40</th>\n      <th>feature_wisdom41</th>\n      <th>feature_wisdom42</th>\n      <th>feature_wisdom43</th>\n      <th>feature_wisdom44</th>\n      <th>feature_wisdom45</th>\n      <th>feature_wisdom46</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n000315175b67977</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.5</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n0014af834a96cdd</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>1.00</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n001c93979ac41d4</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>1.0</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n0034e4143f22a13</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.5</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n00679d1a636062f</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.75</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 314 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GkhBurt73Fi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "aeb5461c-5abd-41e2-92d0-3c151faf8eff"
      },
      "source": [
        "# download the latest tournament dataset (takes around 30s)\n",
        "tournament_data = pd.read_csv(\"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_tournament_data.csv.xz\")\n",
        "tournament_data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id     era   data_type  feature_intelligence1  \\\n",
              "0  n0003aa52cab36c2  era121  validation                   0.25   \n",
              "1  n000920ed083903f  era121  validation                   0.75   \n",
              "2  n0038e640522c4a6  era121  validation                   1.00   \n",
              "3  n004ac94a87dc54b  era121  validation                   0.75   \n",
              "4  n0052fe97ea0c05f  era121  validation                   0.25   \n",
              "\n",
              "   feature_intelligence2  feature_intelligence3  feature_intelligence4  \\\n",
              "0                   0.75                   0.50                   0.50   \n",
              "1                   0.50                   0.75                   1.00   \n",
              "2                   0.00                   0.00                   1.00   \n",
              "3                   1.00                   1.00                   0.50   \n",
              "4                   0.50                   0.50                   0.25   \n",
              "\n",
              "   feature_intelligence5  feature_intelligence6  feature_intelligence7  ...  \\\n",
              "0                    0.0                   0.75                    0.5  ...   \n",
              "1                    0.5                   0.00                    0.0  ...   \n",
              "2                    1.0                   1.00                    1.0  ...   \n",
              "3                    0.0                   0.00                    0.0  ...   \n",
              "4                    1.0                   0.50                    0.5  ...   \n",
              "\n",
              "   feature_wisdom38  feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n",
              "0              0.75              0.75              1.00              0.75   \n",
              "1              0.50              0.50              0.75              1.00   \n",
              "2              0.00              0.00              0.50              0.25   \n",
              "3              0.00              0.00              0.00              0.25   \n",
              "4              0.50              0.75              0.00              0.00   \n",
              "\n",
              "   feature_wisdom42  feature_wisdom43  feature_wisdom44  feature_wisdom45  \\\n",
              "0              0.50               0.5               1.0              0.00   \n",
              "1              0.75               0.5               0.5              0.50   \n",
              "2              0.00               0.0               0.5              0.50   \n",
              "3              0.00               0.0               0.0              0.25   \n",
              "4              0.75               1.0               0.0              0.25   \n",
              "\n",
              "   feature_wisdom46  target  \n",
              "0              0.00    0.25  \n",
              "1              0.50    0.50  \n",
              "2              0.00    1.00  \n",
              "3              0.25    0.50  \n",
              "4              1.00    0.75  \n",
              "\n",
              "[5 rows x 314 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>era</th>\n      <th>data_type</th>\n      <th>feature_intelligence1</th>\n      <th>feature_intelligence2</th>\n      <th>feature_intelligence3</th>\n      <th>feature_intelligence4</th>\n      <th>feature_intelligence5</th>\n      <th>feature_intelligence6</th>\n      <th>feature_intelligence7</th>\n      <th>...</th>\n      <th>feature_wisdom38</th>\n      <th>feature_wisdom39</th>\n      <th>feature_wisdom40</th>\n      <th>feature_wisdom41</th>\n      <th>feature_wisdom42</th>\n      <th>feature_wisdom43</th>\n      <th>feature_wisdom44</th>\n      <th>feature_wisdom45</th>\n      <th>feature_wisdom46</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n0003aa52cab36c2</td>\n      <td>era121</td>\n      <td>validation</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n000920ed083903f</td>\n      <td>era121</td>\n      <td>validation</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n0038e640522c4a6</td>\n      <td>era121</td>\n      <td>validation</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n004ac94a87dc54b</td>\n      <td>era121</td>\n      <td>validation</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n0052fe97ea0c05f</td>\n      <td>era121</td>\n      <td>validation</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>1.0</td>\n      <td>0.50</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>1.00</td>\n      <td>0.75</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 314 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Fcz-PpHYez"
      },
      "source": [
        "## 3. Train your first model\n",
        "Let's create a basic model using sklearn's linear regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESazJMMzN--g"
      },
      "source": [
        "# find only the feature columns\n",
        "feature_cols = training_data.columns[training_data.columns.str.startswith('feature')]\n",
        "# select those columns out of the training dataset\n",
        "training_features = training_data[feature_cols]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = training_features\n",
        "y = training_data['target']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.25 ,random_state=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function that compares the CV perfromance of a set of predetrmined models \n",
        "def cv_comparison(models, X, y, cv):\n",
        "    # Initiate a DataFrame for the averages and a list for all measures\n",
        "    cv_accuracies = pd.DataFrame()\n",
        "    maes = []\n",
        "    mses = []\n",
        "    r2s = []\n",
        "    accs = []\n",
        "    # Loop through the models, run a CV, add the average scores to the DataFrame and the scores of \n",
        "    # all CVs to the list\n",
        "    for model in models:\n",
        "        mae = -np.round(cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv), 4)\n",
        "        maes.append(mae)\n",
        "        mae_avg = round(mae.mean(), 4)\n",
        "        mse = -np.round(cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv), 4)\n",
        "        mses.append(mse)\n",
        "        mse_avg = round(mse.mean(), 4)\n",
        "        r2 = np.round(cross_val_score(model, X, y, scoring='r2', cv=cv), 4)\n",
        "        r2s.append(r2)\n",
        "        r2_avg = round(r2.mean(), 4)\n",
        "        acc = np.round((100 - (100 * (mae * len(X))) / sum(y)), 4)\n",
        "        accs.append(acc)\n",
        "        acc_avg = round(acc.mean(), 4)\n",
        "        cv_accuracies[str(model)] = [mae_avg, mse_avg, r2_avg, acc_avg]\n",
        "    cv_accuracies.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2', 'Accuracy']\n",
        "    return cv_accuracies, maes, mses, r2s, accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the models to be tested\n",
        "mlr_reg = LinearRegression()\n",
        "rf_reg = RandomForestRegressor(random_state=42)\n",
        "xgb_reg = xgb_regressor = xgb.XGBRegressor(random_state=42)\n",
        "\n",
        "# Put the models in a list to be used for Cross-Validation\n",
        "models = [mlr_reg, rf_reg, xgb_reg]\n",
        "\n",
        "# Run the Cross-Validation comparison with the models used in this analysis\n",
        "comp, maes, mses, r2s, accs = cv_comparison(models, X_train, y_train, 4)\n",
        "comp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    1st Fold  2nd Fold  \\\n",
              "LinearRegression(copy_X=True, fit_intercept=Tru...   -0.0018   -0.0013   \n",
              "RandomForestRegressor(bootstrap=True, ccp_alpha...   -0.0268   -0.0233   \n",
              "XGBRegressor(base_score=None, booster=None, col...   -0.0526   -0.0513   \n",
              "\n",
              "                                                    3rd Fold  4th Fold  \\\n",
              "LinearRegression(copy_X=True, fit_intercept=Tru...   -0.0002    0.0010   \n",
              "RandomForestRegressor(bootstrap=True, ccp_alpha...   -0.0234   -0.0199   \n",
              "XGBRegressor(base_score=None, booster=None, col...   -0.0523   -0.0529   \n",
              "\n",
              "                                                    Average  \n",
              "LinearRegression(copy_X=True, fit_intercept=Tru...  -0.0006  \n",
              "RandomForestRegressor(bootstrap=True, ccp_alpha...  -0.0234  \n",
              "XGBRegressor(base_score=None, booster=None, col...  -0.0523  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1st Fold</th>\n      <th>2nd Fold</th>\n      <th>3rd Fold</th>\n      <th>4th Fold</th>\n      <th>Average</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)</th>\n      <td>-0.0018</td>\n      <td>-0.0013</td>\n      <td>-0.0002</td>\n      <td>0.0010</td>\n      <td>-0.0006</td>\n    </tr>\n    <tr>\n      <th>RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\\n                      max_depth=None, max_features='auto', max_leaf_nodes=None,\\n                      max_samples=None, min_impurity_decrease=0.0,\\n                      min_impurity_split=None, min_samples_leaf=1,\\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\\n                      n_estimators=100, n_jobs=None, oob_score=False,\\n                      random_state=42, verbose=0, warm_start=False)</th>\n      <td>-0.0268</td>\n      <td>-0.0233</td>\n      <td>-0.0234</td>\n      <td>-0.0199</td>\n      <td>-0.0234</td>\n    </tr>\n    <tr>\n      <th>XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\\n             colsample_bynode=None, colsample_bytree=None, gamma=None,\\n             gpu_id=None, importance_type='gain', interaction_constraints=None,\\n             learning_rate=None, max_delta_step=None, max_depth=None,\\n             min_child_weight=None, missing=nan, monotone_constraints=None,\\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\\n             objective='reg:squarederror', random_state=42, reg_alpha=None,\\n             reg_lambda=None, scale_pos_weight=None, subsample=None,\\n             tree_method=None, validate_parameters=None, verbosity=None)</th>\n      <td>-0.0526</td>\n      <td>-0.0513</td>\n      <td>-0.0523</td>\n      <td>-0.0529</td>\n      <td>-0.0523</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Create DataFrame for all R^2s\n",
        "r2_comp = pd.DataFrame(r2s, index=comp.columns, columns=['1st Fold', '2nd Fold', '3rd Fold', \n",
        "                                                         '4th Fold'])\n",
        "\n",
        "# Add a column for the averages\n",
        "r2_comp['Average'] = np.round(r2_comp.mean(axis=1),4)\n",
        "r2_comp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Number of trees in Random Forest\n",
        "rf_n_estimators = [int(x) for x in np.linspace(200, 1000, 5)]\n",
        "rf_n_estimators.append(1500)\n",
        "rf_n_estimators.append(2000)\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "rf_max_depth = [int(x) for x in np.linspace(5, 55, 11)]\n",
        "# Add the default as a possible value\n",
        "rf_max_depth.append(None)\n",
        "\n",
        "# Number of features to consider at every split\n",
        "rf_max_features = ['auto', 'sqrt', 'log2']\n",
        "\n",
        "# Criterion to split on\n",
        "rf_criterion = ['mse', 'mae']\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "rf_min_samples_split = [int(x) for x in np.linspace(2, 10, 9)]\n",
        "\n",
        "# Minimum decrease in impurity required for split to happen\n",
        "rf_min_impurity_decrease = [0.0, 0.05, 0.1]\n",
        "\n",
        "# Method of selecting samples for training each tree\n",
        "rf_bootstrap = [True, False]\n",
        "\n",
        "# Create the grid\n",
        "rf_grid = {'n_estimators': rf_n_estimators,\n",
        "               'max_depth': rf_max_depth,\n",
        "               'max_features': rf_max_features,\n",
        "               'criterion': rf_criterion,\n",
        "               'min_samples_split': rf_min_samples_split,\n",
        "               'min_impurity_decrease': rf_min_impurity_decrease,\n",
        "               'bootstrap': rf_bootstrap}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ]
        }
      ],
      "source": [
        "# Create the model to be tuned\n",
        "rf_base = RandomForestRegressor()\n",
        "\n",
        "# Create the random search Random Forest\n",
        "rf_random = RandomizedSearchCV(estimator = rf_base, param_distributions = rf_grid, \n",
        "                               n_iter = 200, cv = 3, verbose = 2, random_state = 42, \n",
        "                               n_jobs = -1)\n",
        "\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "# View the best parameters from the random search\n",
        "rf_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Number of trees to be used\n",
        "xgb_n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "xgb_max_depth = [int(x) for x in np.linspace(2, 20, 10)]\n",
        "\n",
        "# Minimum number of instaces needed in each node\n",
        "xgb_min_child_weight = [int(x) for x in np.linspace(1, 10, 10)]\n",
        "\n",
        "# Tree construction algorithm used in XGBoost\n",
        "xgb_tree_method = ['auto', 'exact', 'approx', 'hist', 'gpu_hist']\n",
        "\n",
        "# Learning rate\n",
        "xgb_eta = [x for x in np.linspace(0.1, 0.6, 6)]\n",
        "\n",
        "# Minimum loss reduction required to make further partition\n",
        "xgb_gamma = [int(x) for x in np.linspace(0, 0.5, 6)]\n",
        "\n",
        "# Learning objective used\n",
        "xgb_objective = ['reg:squarederror', 'reg:squaredlogerror']\n",
        "\n",
        "# Create the grid\n",
        "xgb_grid = {'n_estimators': xgb_n_estimators,\n",
        "            'max_depth': xgb_max_depth,\n",
        "            'min_child_weight': xgb_min_child_weight,\n",
        "            'tree_method': xgb_tree_method,\n",
        "            'eta': xgb_eta,\n",
        "            'gamma': xgb_gamma,\n",
        "            'objective': xgb_objective}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the model to be tuned\n",
        "xgb_base = xgb.XGBRegressor()\n",
        "\n",
        "# Create the random search Random Forest\n",
        "xgb_random = RandomizedSearchCV(estimator = xgb_base, param_distributions = xgb_grid, \n",
        "                                n_iter = 200, cv = 3, verbose = 2, \n",
        "                                random_state = 420, n_jobs = -1)\n",
        "\n",
        "# Fit the random search model\n",
        "xgb_random.fit(X_train, y_train)\n",
        "\n",
        "# Get the optimal parameters\n",
        "xgb_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the final Multiple Linear Regression\n",
        "mlr_final = LinearRegression()\n",
        "\n",
        "# Create the final Random Forest\n",
        "rf_final = RandomForestRegressor(n_estimators = 200,\n",
        "                                 min_samples_split = 6,\n",
        "                                 min_impurity_decrease = 0.0,\n",
        "                                 max_features = 'sqrt',\n",
        "                                 max_depth = 25,\n",
        "                                 criterion = 'mae',\n",
        "                                 bootstrap = True,\n",
        "                                 random_state = 42)\n",
        "\n",
        "# Create the fnal Extreme Gradient Booster\n",
        "xgb_final = xgb.XGBRegressor(tree_method = 'exact',\n",
        "                         objective = 'reg:squarederror',\n",
        "                         n_estimators = 1600,\n",
        "                         min_child_weight = 6,\n",
        "                         max_depth = 8,\n",
        "                         gamma = 0,\n",
        "                         eta = 0.1,\n",
        "                         random_state = 42)\n",
        "\n",
        "# Train the models using 80% of the original data\n",
        "mlr_final.fit(X_train, y_train)\n",
        "rf_final.fit(X_train, y_train)\n",
        "xgb_final.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function that compares all final models\n",
        "def final_comparison(models, test_features, test_labels):\n",
        "    scores = pd.DataFrame()\n",
        "    for model in models:\n",
        "        predictions = model.predict(test_features)\n",
        "        mae = round(mean_absolute_error(test_labels, predictions), 4)\n",
        "        mse = round(mean_squared_error(test_labels, predictions), 4)\n",
        "        r2 = round(r2_score(test_labels, predictions), 4)\n",
        "        errors = abs(predictions - test_labels)\n",
        "        mape = 100 * np.mean(errors / test_labels)\n",
        "        accuracy = round(100 - mape, 4)\n",
        "        scores[str(model)] = [mae, mse, r2, accuracy]\n",
        "    scores.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2', 'Accuracy']\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call the comparison function with the three final models\n",
        "final_scores = final_comparison([mlr_final, rf_final, xgb_final], X_test, y_test)\n",
        "\n",
        "# Adjust the column headers\n",
        "final_scores.columns  = ['Linear Regression', 'Random Forest', 'Extreme Gradient Boosting']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxx5pLIGIUvN"
      },
      "source": [
        "## 4. Generate your first predictions\n",
        "Now that we have a trained model, we can use it to make predictions on the tournament data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIcmOiJYSmJI"
      },
      "source": [
        "# select the feature columns from the tournament data\n",
        "live_features = tournament_data[feature_cols]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4CoaCgbKcSN"
      },
      "source": [
        "# predict the target on the live features\n",
        "predictions = model.predict(live_features)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L4BFeAzTTDe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "692b78f5-20b1-4431-8d53-ceef876f8101"
      },
      "source": [
        "# predictions must have an `id` column and a `prediction_kazutsugi` column\n",
        "predictions_df = tournament_data[\"id\"].to_frame()\n",
        "predictions_df[\"prediction_kazutsugi\"] = predictions\n",
        "predictions_df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id  prediction_kazutsugi\n",
              "0  n0003aa52cab36c2              0.514920\n",
              "1  n000920ed083903f              0.503874\n",
              "2  n0038e640522c4a6              0.576218\n",
              "3  n004ac94a87dc54b              0.528573\n",
              "4  n0052fe97ea0c05f              0.461963"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction_kazutsugi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n0003aa52cab36c2</td>\n      <td>0.514920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n000920ed083903f</td>\n      <td>0.503874</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n0038e640522c4a6</td>\n      <td>0.576218</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n004ac94a87dc54b</td>\n      <td>0.528573</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n0052fe97ea0c05f</td>\n      <td>0.461963</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ0sgtPiLDys"
      },
      "source": [
        "## 5. Make your first submission\n",
        "To enter the tournament, we must submit the predictions back to Numerai. We will use the `numerapi` library to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEfqpxcEWDdK"
      },
      "source": [
        "# Get your API keys and model_id from https://numer.ai/submit\n",
        "public_id = \"OKZD5PCCEHGLF4LFJGNJDAY2HUXF2XPV\"\n",
        "secret_key = \"43R6IGFPZ6OCVKTL6VBG3YIV23GBDRE46FNVVRCWQX24VUZWEKAPVYJPG5UFUUGO\"\n",
        "model_id = \"707b215d-4330-44a9-873c-b2ac2ff0e3de\"\n",
        "napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeAIJHaoW3VU"
      },
      "source": [
        "# Upload your predictions\n",
        "predictions_df.to_csv(\"predictions.csv\", index=False)\n",
        "submission_id = napi.upload_predictions(\"predictions.csv\", model_id=model_id)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-02-23 07:51:03,336 INFO numerapi.base_api: uploading predictions...\n",
            "2021-02-23 07:51:44,365 ERROR numerapi.base_api: Can't update submission after deadline if previous submission was on time\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Can't update submission after deadline if previous submission was on time",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-29-efc87f6ec4fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Upload your predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpredictions_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predictions.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msubmission_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predictions.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numerapi\\numerapi.py\u001b[0m in \u001b[0;36mupload_predictions\u001b[1;34m(self, file_path, tournament, model_id)\u001b[0m\n\u001b[0;32m    844\u001b[0m                      \u001b[1;34m'tournament'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtournament\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m                      'modelId': model_id}\n\u001b[1;32m--> 846\u001b[1;33m         \u001b[0mcreate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthorization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m         \u001b[0msubmission_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_submission'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msubmission_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numerapi\\base_api.py\u001b[0m in \u001b[0;36mraw_query\u001b[1;34m(self, query, variables, authorization)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_call_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;31m# fail!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Can't update submission after deadline if previous submission was on time"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jc2NgEgQEKF"
      },
      "source": [
        "# Done 🚀\n",
        "Good job! You just made your first submission on Numerai!\n",
        "\n",
        "Head back over to https://numer.ai/submit to continue."
      ]
    }
  ]
}